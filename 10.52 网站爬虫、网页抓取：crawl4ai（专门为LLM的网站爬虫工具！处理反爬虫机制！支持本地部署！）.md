
【参考】
https://brightdata.com/blog/ai/crawl4ai-vs-firecrawl

然而，Crawl4AI 的抓取方式仅限于 Markdown 和原始 HTML，这已经是相当简洁的了。虽然 Crawl4AI 声称支持[在不使用 LLM 的情况下提取 JSON 数据](https://docs.crawl4ai.com/extraction/no-llm-strategies/)，但这种支持非常有限且存在缺陷。要提取完整的数据结构，您需要在代码中添加 LLM 支持。这就是 Crawl4AI 的隐性成本：您需要托管或付费使用外部 LLM 才能完成真正的解析任务。


# 【Docker的方式来部署这个crawl4ai】

![image.png](https://repo.in4tree.com/2026/02/04_1770271481669.png)

![image.png](https://repo.in4tree.com/2026/02/04_1770271557721.png)

![image.png](https://repo.in4tree.com/2026/02/04_1770271742530.png)

![image.png](https://repo.in4tree.com/2026/02/04_1770271828492.png)

# 【n8n工作流】

## 添加Http请求节点，读取网站的sitemap.xml中全部网页url


## 添加一个xml节点，转换xml为Json格式


## 添加一个Split节点，Json分割为数组


## 添加Limit节点：避免引发反爬虫机制！


## 添加Loop节点


## 添加Http请求节点，调用**crawl4ai**获取url网页内容

### 创建**crawl4ai的抓取任务（Task ID）**

我们要使用这个host.docker.internal，当然这里也可以使用反向代理？？？？？

？？？设置**crawl4ai**

执行，获得taskID

### 调用crawl4ai第二个API，真正去抓取网页内容

![image.png](https://repo.in4tree.com/2026/02/05_1770278613590.png)

## 添加If节点，根据返回状态做相应处理，失败后，重新抓取

![image.png](https://repo.in4tree.com/2026/02/05_1770278570865.png)




---
# 【参考】

AI最强辅助！n8n+crawl4ai工作流，一键抓取任意网站！搭建RAG知识库+MCP自动化，让你的AI更准！更强
https://www.youtube.com/watch?v=Y6C7kpNSrd4
